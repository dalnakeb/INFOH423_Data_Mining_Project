{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08671a88-a2ed-4626-9559-489020c1aca3",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4273819c-233f-4a05-b227-a03ddb2c919b",
   "metadata": {},
   "source": [
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1ca7bf-3b05-429d-b6e0-2dcc26028a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import posixpath\n",
    "import data\n",
    "import eda\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import plotly.express as px\n",
    "\n",
    "DATA_PATH = \"C:\\\\Users\\\\derar\\\\Documents\\\\Data Mining Project\\\\Code\\\\data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b8d810-34f2-40ef-872f-08e283e68442",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04458b5-3dd9-4ee5-8b3a-1262f18b0ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"sncb_data_challenge.csv\"  \n",
    "file_path = posixpath.join(DATA_PATH, file_name)\n",
    "data_df = data.load_data_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e65c9f0-858e-4d74-9c24-17a620fa166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3843be4f-3946-4958-a769-1ca3e8916e61",
   "metadata": {},
   "source": [
    "## Event filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c762b470-25ac-4a3a-a52b-295c49144da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd762b20-cc09-4bea-b0b0-f1cab722ea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_events_freq(events_sequence):\n",
    "    unique_events, events_count = np.unique(events_sequence, return_counts=True)\n",
    "    total_events_count = np.sum(events_count)\n",
    "    events_freq = events_count / total_events_count\n",
    "    events_freq = np.column_stack((unique_events, events_freq))\n",
    "    events_freq = {int(k): v for k, v in events_freq}\n",
    "    return events_freq\n",
    "\n",
    "def compute_events_to_remove(data_df, events_freq_all_classes, t):\n",
    "    events_to_remove = {}\n",
    "    events_freq_per_incident = {}\n",
    "    for incident_type, events_sequences in list(data_df.groupby(\"incident_type\")[\"events_sequence\"]):\n",
    "        events_sequence_per_incident = np.concatenate(events_sequences.to_list())\n",
    "        events_freq_per_incident[incident_type] = compute_events_freq(events_sequence_per_incident)\n",
    "\n",
    "    for incident_type, events_freq in events_freq_per_incident.items():\n",
    "        events_to_remove[incident_type] = []\n",
    "        for event_id, event_freq in events_freq.items():\n",
    "            if event_freq/events_freq_all_classes[event_id] < t:\n",
    "                events_to_remove[incident_type].append(event_id) \n",
    "\n",
    "    return events_to_remove\n",
    "\n",
    "def remove_event_from_incidents(data_df, events_to_remove_per_incident, allowed_event=None):\n",
    "    def remove_events(row, list_columns_indices, events_to_remove_per_incident, allowed_event=None):\n",
    "        row_index = row.iloc[0]\n",
    "        incident_type = row.iloc[-1]\n",
    "        \n",
    "        print(row_index)\n",
    "        events_to_remove = events_to_remove_per_incident[incident_type]\n",
    "        for event_id in events_to_remove:\n",
    "            removed_event_indices = row.iloc[3] == event_id \n",
    "            for col in list_columns_indices:\n",
    "                row.iloc[col] = row.iloc[col][~removed_event_indices]\n",
    "        return row\n",
    "    \n",
    "    filtered_data_df = data_df.copy()\n",
    "    list_columns = [\"vehicles_sequence\", \"events_sequence\", \"seconds_to_incident_sequence\", \"train_kph_sequence\", \"dj_ac_state_sequence\", \"dj_dc_state_sequence\"]\n",
    "    list_columns_indices = []\n",
    "    for el in list_columns:\n",
    "        list_columns_indices.append(data_df.columns.to_list().index(el))\n",
    "        \n",
    "    filtered_data_df = filtered_data_df.apply(lambda row: remove_events(row, list_columns_indices, events_to_remove_per_incident, allowed_event), axis=1)\n",
    "    return filtered_data_df\n",
    "    \n",
    "\n",
    "def filter_events(data_df, t, allowed_event=None):\n",
    "    events_sequences_all_classes = np.concatenate(list(data_df[\"events_sequence\"]))\n",
    "    events_freq_all_classes = compute_events_freq(events_sequences_all_classes)\n",
    "    events_to_remove_per_incident = compute_events_to_remove(data_df, events_freq_all_classes, t)\n",
    "    filtered_data_df = remove_event_from_incidents(data_df, events_to_remove_per_incident, allowed_event)\n",
    "    return filtered_data_df\n",
    "    \n",
    "filtered_data_df = filter_events(data_df, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed22a0-7e18-4228-8f2f-1f70e8fa5411",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_df[\"events_sequence\"] == data_df[\"events_sequence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a47111-d150-4dff-b589-6d1ad302672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcss(data_df, time_interval,incident_type):\n",
    "    sub_data= data_df[data_df['incident_type'] == incident_type]\n",
    "    subsequences_per_row = {}  # Dictionary to store subsequences per row\n",
    "    events_sequence = sub_data['events_sequence'].to_numpy()  # Convert to NumPy array\n",
    "    time_sequence = sub_data['seconds_to_incident_sequence'].to_numpy()  # Convert timestamps to NumPy array\n",
    "    \n",
    "    start_time, end_time = time_interval  # Extract start and end of interval\n",
    "\n",
    "    for row_idx, (events, times) in enumerate(zip(events_sequence, time_sequence)):\n",
    "        list_of_ss = []  # List to store subsequences for the current row\n",
    "        ss = []  # Temporary list to build subsequences\n",
    "        \n",
    "        # Filter events based on time interval and duplicate removal\n",
    "        filtered_events = [event for event, time in zip(events, times) if start_time <= time <= end_time]\n",
    "        ss_list = [filtered_events[0]]\n",
    "        for event in filtered_events:\n",
    "            if event != ss_list[-1]:\n",
    "                ss_list.append(event) \n",
    "\n",
    "        # Generate all possible subsequences\n",
    "        all_ss_list_wd = []\n",
    "        n = len(ss_list)\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n + 1):\n",
    "                if len(ss_list[i:j]) >= 2:\n",
    "                    all_ss_list_wd.append(ss_list[i:j])\n",
    "\n",
    "        # Duplicate removal for all subsequences\n",
    "        all_ss_list = [all_ss_list_wd[0]] if all_ss_list_wd else []\n",
    "        for subsequence in all_ss_list_wd[1:]:\n",
    "            if subsequence not in all_ss_list:\n",
    "                all_ss_list.append(subsequence)\n",
    "\n",
    "        # Store subsequences for the current row\n",
    "        subsequences_per_row[row_idx] = all_ss_list\n",
    "\n",
    "    # Find the longest common subsequence (LCSS)\n",
    "    if len(subsequences_per_row) == 0:\n",
    "        return None  # If no sequences are available\n",
    "\n",
    "    checking_list = subsequences_per_row[0]\n",
    "    common_subsequences = []\n",
    "    for subsequence in checking_list:\n",
    "        is_common = True\n",
    "        for i in range(1, len(subsequences_per_row)):\n",
    "            if subsequence not in subsequences_per_row[i]:\n",
    "                is_common = False\n",
    "                break\n",
    "        if is_common:\n",
    "            common_subsequences.append(subsequence)\n",
    "\n",
    "    if len(common_subsequences) == 0:  # If no common subsequences are found\n",
    "        return None\n",
    "    else:\n",
    "        longest_common_subsequence = common_subsequences[0]\n",
    "        for subsequence in common_subsequences:\n",
    "            if len(subsequence) > len(longest_common_subsequence):\n",
    "                longest_common_subsequence = subsequence\n",
    "        return longest_common_subsequence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d8c762-48bf-4a4e-9da2-74d117e35fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
