{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6ef8af3-fbe2-4f2f-9c90-465452563035",
   "metadata": {},
   "source": [
    "# Model LSTM (Incomplete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4493b0d7-5317-4e1f-a01c-4395dc3e33ea",
   "metadata": {},
   "source": [
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe7f4d0-b65d-4479-8aed-04dfba7a4c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import posixpath\n",
    "from data_mining_project import data, PROJECT_PATH, DATA_PATH, OUTPUT_PATH\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import plotly.express as px\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808a4030-42b8-4b37-96b7-0da81331f743",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d31462-0f09-4665-a118-b061de657082",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"preprocessed_data.csv\"  \n",
    "file_path = posixpath.join(OUTPUT_PATH, file_name)\n",
    "data_df = data.load_data_csv(file_path)\n",
    "data_df = data.reformat_str_to_list(data_df, cols=[\"events_sequence\", \"seconds_to_incident_sequence\", \"dj_ac_state_sequence\", \"dj_dc_state_sequence\", \"ac_dc_prob_timestamp\"], col_type=int)\n",
    "data_df = data.reformat_str_to_list(data_df, cols=[\"train_kph_sequence\"], col_type=float)\n",
    "data_df.drop(columns=[\"ac_dc_prob_num\", \"ac_dc_prob\"], inplace=True)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9a876d-5365-46bf-a05d-ecdd4cc833d7",
   "metadata": {},
   "source": [
    "## Add timestamp_diff column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b16d37-7eb7-4b9f-84c4-bc2b8468836d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_timestamp_diff(x):\n",
    "    new_x = np.zeros(x.shape[0])\n",
    "    for i in range(1, x.shape[0]):\n",
    "        new_x[i] = x[i] - x[i-1]\n",
    "    return new_x\n",
    "    \n",
    "data_df.insert(1, \"timestamp_diff\", data_df[\"seconds_to_incident_sequence\"].apply(compute_timestamp_diff))\n",
    "data_df.drop(columns=[\"seconds_to_incident_sequence\"],inplace=True)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c7a1e3-3fad-41a4-bca1-7e79d321276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop(columns=[\"timestamp_diff\",\"train_kph_sequence\", \"dj_ac_state_sequence\", \"dj_dc_state_sequence\", \"ac_dc_prob_timestamp\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ed02dc-1ae0-4f20-a567-7675dbccfd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "XY = data_df.to_numpy()\n",
    "XY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad5f694-9224-41a6-afa7-a1846278fc21",
   "metadata": {},
   "source": [
    "## Padding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130c4d7e-558e-4341-bc54-bc74a2bdc1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = XY[:, :-1]\n",
    "max_len = max(x[0].shape[0] for x in X)\n",
    "new_X = np.empty((X.shape[0], X.shape[1], max_len), dtype=object)\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    new_X[i] = pad_sequences(X[i], maxlen=max_len, padding=\"post\")\n",
    "    \n",
    "X = new_X\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87240e10-e9f5-4228-9f10-a4e3b1231758",
   "metadata": {},
   "source": [
    "## Converting data types into consecutive number encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066359df-7620-4437-82f8-cbd6e194fd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_type_mapping = {x: i for i, x in enumerate(np.unique(X))}\n",
    "X = np.vectorize(event_type_mapping.get)(X)\n",
    "print(np.unique(X).shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e639f0c-cbb0-44bd-a561-740636af3a35",
   "metadata": {},
   "source": [
    "## Concatenating columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3748611-6bd7-4e3c-a1f8-9b2b392f2f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((X.shape[0], X.shape[1]*X.shape[2]))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840f4ab9-f76a-4021-ab06-a7a4ea5928a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5f822d-d8b5-41ad-8fed-f76366ee8f53",
   "metadata": {},
   "source": [
    "## Converting labels to one-hot encoding\n",
    "### Map each incident type to consecutive number encoding at first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a73ab-841e-4a58-a749-5f5b3362ea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = XY[:, -1]\n",
    "incident_type_mapping = {x: i for i, x in enumerate(np.unique(Y))}\n",
    "Y = np.array([incident_type_mapping[incident] for incident in Y])\n",
    "#Y = np.eye(np.unique(Y).shape[0])[Y]\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099a06ec-c92f-47e2-b793-a64a6b2d9708",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6f9ae7-91fb-4b3f-92a7-0afa214bdec1",
   "metadata": {},
   "source": [
    "### Split data into overlapping sequences of size S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9da620-c2d9-4377-a06d-30307cecf224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_seq(X, S, step):\n",
    "    new_X = []\n",
    "    print(X.shape)\n",
    "    for i in range(X.shape[0]):\n",
    "        new_X.append(np.array([X[i][j:j + S] for j in range(0, X.shape[1] - S + 1, step)]))\n",
    "            \n",
    "    return np.array(new_X)\n",
    "\n",
    "X_tr = X[:int(X.shape[0]*.75), :].astype(\"float64\")\n",
    "S = 16\n",
    "X_tr = split_seq(X_tr, S=S, step=S)\n",
    "\n",
    "Y_tr = Y[:int(Y.shape[0]*.75)].astype(\"float64\")\n",
    "print(X_tr.shape)\n",
    "print(Y_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348009d2-5658-4db8-bc08-0800b58766fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_tr, Y_tr, num_classes, voc_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=voc_size, output_dim=128, mask_zero=True))\n",
    "    model.add(LSTM(units=128, activation=\"relu\", return_sequences=False, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.summary()\n",
    "    model.compile(loss='sparse_categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=5)\n",
    "    model.fit(X_tr, Y_tr, epochs=20, batch_size=32,\n",
    "              verbose=1, callback = [callback])\n",
    "    \n",
    "    return model\n",
    "X_tr = X[:int(X.shape[0]*0.75), :-1].astype(\"float64\")    \n",
    "voc_size = np.unique(X).shape[0]\n",
    "num_classes = np.unique(Y).shape[0]\n",
    "model = train_model(X_tr, Y_tr, num_classes=num_classes, voc_size=voc_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c766a8-75ab-4879-8412-bdedec50f911",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273cf113-64a5-478b-af11-1f75dd819880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(X_ts, model):\n",
    "    Y_hat_ts = model.predict(X_ts)\n",
    "    return Y_hat_ts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
